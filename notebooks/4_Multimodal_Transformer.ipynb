{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nanopiero/PREAC/blob/main/notebooks/Multimodal_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Atelier 4 : Régression multimodale avec un Visual Transformer\n"
      ],
      "metadata": {
        "id": "-1ciEeyNevrd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mU0zdFYCLdgR"
      },
      "outputs": [],
      "source": [
        "# Imports des bibliothèques utiles\n",
        "# pour l'IA\n",
        "import torch\n",
        "# pour les maths\n",
        "import numpy as np\n",
        "# pour afficher des images et des courbes\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/nanopiero/PREAC.git"
      ],
      "metadata": {
        "id": "5zHe5if9b8Yn",
        "outputId": "14526362-4468-4709-c3b8-dad7a0c6f709",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'PREAC'...\n",
            "remote: Enumerating objects: 87, done.\u001b[K\n",
            "remote: Counting objects: 100% (87/87), done.\u001b[K\n",
            "remote: Compressing objects: 100% (84/84), done.\u001b[K\n",
            "remote: Total 87 (delta 40), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (87/87), 7.17 MiB | 10.81 MiB/s, done.\n",
            "Resolving deltas: 100% (40/40), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A. Découverte du problème"
      ],
      "metadata": {
        "id": "iXg4IwvHDSyY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install einops"
      ],
      "metadata": {
        "id": "ryjHWMbzMMGw",
        "outputId": "91892af1-049f-446c-ebc3-a0d6fcbefe8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting einops\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PREAC.utile_Transformers import voir_batch2D, gen_image_with_pairs, set_tensor_values\n",
        "\n",
        "# Notre jeu de données contient:\n",
        "# une cible parfaite (lamedeau)\n",
        "# des triplets \"pluviometres\" :\n",
        "# (lon_pluvio, lat_pluvio, taux de pluie mesuré)\n",
        "# des quintuplets \"cmls\" associés aux antennes A & B:\n",
        "# (lon_A, lat_A, lat_B, lon_B, taux de pluie moyen entre A et B)\n",
        "\n",
        "batch_size = 6\n",
        "n_pairs = 16\n",
        "n_points = 16\n",
        "lamedeau, pluviometres, radar, cmls_spatialises, cmls = gen_image_with_pairs(6, n_pairs, n_points)\n",
        "\n",
        "# lame d'eau \"idéale\"\n",
        "fig1 = plt.figure(1, figsize=(36, 6))\n",
        "voir_batch2D(lamedeau, 6, fig1, k=0, min_scale=0, max_scale=1)\n",
        "\n",
        "# images radar (bruitées)\n",
        "fig2 = plt.figure(2, figsize=(36, 6))\n",
        "voir_batch2D(radar, 6, fig2, k=0, min_scale=0, max_scale=1)\n",
        "\n",
        "# Commercial Microwave Links (cmls)\n",
        "fig3 = plt.figure(3, figsize=(36, 6))\n",
        "voir_batch2D(cmls_spatialises, 6, fig3, k=0, min_scale=0, max_scale=1)\n",
        "\n",
        "# Superposition Commercial Microwave Links (CMLs), pluviomètres et radar\n",
        "fig4 = plt.figure(4, figsize=(36, 6))\n",
        "cmls_spatialises = set_tensor_values(cmls_spatialises, pluviometres, 64)\n",
        "radar[cmls_spatialises > 0] = cmls_spatialises[cmls_spatialises > 0 ]\n",
        "voir_batch2D(radar, 6, fig4, k=0, min_scale=0., max_scale=1.2)\n"
      ],
      "metadata": {
        "id": "pd1BiavmQnmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Questions intéressantes** : \\\\\n",
        "Pourquoi est-ce que le temps de génération des images est long la première fois qu'on lance le code, mais pas les suivantes ? \\\\\n",
        "En quoi les cmls et les pluviomètres peuvent-ils aider à atteindre la cible (c'est à dire la lame d'eau complète) ? \\\\"
      ],
      "metadata": {
        "id": "4akdeY1sMfZ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## B. Traitement par FCN"
      ],
      "metadata": {
        "id": "0vWPJFKbNkxI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A partir des ateliers précédents, il est possible de définir\n",
        "une approche simple permettant de combiner les trois sources d'information.\n",
        "Seule obstacle : comment concaténer les entrées. D'où le code suivant:"
      ],
      "metadata": {
        "id": "MhLMSBf0NsiI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lamedeau, pluviometres, radar, cmls_spatialises, cmls = gen_image_with_pairs(6, n_pairs, n_points)"
      ],
      "metadata": {
        "id": "O50-ECmBOprA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lamedeau, pluviometres, radar, cmls_spatialises, cmls = gen_image_with_pairs(6, n_pairs, n_points)\n",
        "pluviometres_spatialises =  -0.1 * torch.ones(radar.shape)\n",
        "pluviometres_spatialises = set_tensor_values(pluviometres_spatialises, pluviometres, 64)\n",
        "input = torch.cat([radar, pluviometres_spatialises, cmls_spatialises], dim = 1)\n",
        "print(input.shape)"
      ],
      "metadata": {
        "id": "Us1CXcEmenW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Questions intéressantes** : \\\\\n",
        "Pourquoi est-ce qu'on créé une matrice de -0.1 pour les pluviomètres spatialisés ? \\\\\n",
        "Comment instancier un UNet pour prendre ce type d'input en entrée ? \\\\\n",
        "Visualiser les sorties au bout de cinquante époques (100 batches de 32 par époque)."
      ],
      "metadata": {
        "id": "-2YP1EJpO-G4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## C. Encodage des différentes variables qui vont alimenter le transformer"
      ],
      "metadata": {
        "id": "Y5w49rrAPvAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paramètres du modèle :\n",
        "image_size = [64,64]\n",
        "channels = 1\n",
        "patch_size = 4\n",
        "d_model = 120\n",
        "mlp_expansion_ratio = 4\n",
        "d_ff = mlp_expansion_ratio * d_model\n",
        "n_heads = 4\n",
        "n_layers = 12"
      ],
      "metadata": {
        "id": "AGSx5D5Xr_MR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Module interne du réseau responsable de l'encodage des variables :\n",
        "from PREAC.utile_Transformers import UnifiedEmbedding\n",
        "ue = UnifiedEmbedding(d_model, patch_size, channels)\n"
      ],
      "metadata": {
        "id": "bhL3zpLWQatB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lamedeau, pluviometres, radar, cmls_spatialises, cmls = gen_image_with_pairs(6, n_pairs, n_points)\n",
        "embeddings = ue(radar, pluviometres, cmls)\n",
        "print(embeddings.shape)"
      ],
      "metadata": {
        "id": "VI6mxpedr5j2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question intéressante** : \\\\\n",
        "Comment interpréter les dimensions de l'input après encodage ? \\\\\n"
      ],
      "metadata": {
        "id": "dikHaT2GRXXA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## D. Entraînement du Transformer"
      ],
      "metadata": {
        "id": "wW2g1ZyfR9RY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PREAC.utile_Transformers import FusionTransformer\n",
        "model = FusionTransformer(image_size, patch_size, n_layers, d_model, d_ff, n_heads, channels=1)\n",
        "lamedeau, pluviometres, radar, cmls_spatialises, cmls = gen_image_with_pairs(6, n_pairs, n_points)\n",
        "model(radar, pluviometres, cmls).shape"
      ],
      "metadata": {
        "id": "yUrHDDikx0on"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def criterion(output, target):\n",
        "    return torch.abs((output - target)).mean()\n",
        "\n",
        "import torch.optim as optim\n",
        "optimizer = optim.Adam(model.parameters(), 10**(-4))"
      ],
      "metadata": {
        "id": "9YqVQXoj7cic"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nepochs = 50\n",
        "nbatches = 100\n",
        "batchsize = 32\n",
        "train_losses = []\n",
        "device = torch.device('cuda:0')\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "for epoch in range(nepochs):\n",
        "    print(f\"Epoch {epoch + 1}/{nepochs}\")\n",
        "\n",
        "    epoch_losses = []\n",
        "\n",
        "    for i in range(nbatches):\n",
        "\n",
        "        ...\n",
        "\n",
        "        epoch_losses.append(loss.detach().cpu().item())\n",
        "\n",
        "    epoch_loss = np.mean(epoch_losses)\n",
        "    train_losses.append(epoch_loss)\n",
        "\n",
        "    print(f'Epoch loss: {epoch_loss:.4f}')\n"
      ],
      "metadata": {
        "id": "OQ83-bQy7gQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Questions intéressantes** : \\\\\n",
        "Quelle différence qualitative entre les outputs ? \\\\\n",
        "Que doit faire le transformer \"en plus\", comparé au FCN ?\n",
        "\n"
      ],
      "metadata": {
        "id": "0g_5Mcu5TCnI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## E. Chargement d'un Transformer entraîné"
      ],
      "metadata": {
        "id": "46iifY4CTclo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Avec France Transfert ??\n",
        "# !curl 'https://francetransfert.numerique.gouv.fr/api-private/download-module/generate-download-url' -X POST \\\n",
        "# -H 'Content-Type: application/json' \\\n",
        "# -H 'Origin:https://francetransfert.numerique.gouv.fr' \\\n",
        "# --data-raw '{\"enclosure\":\"164ea132-cf5e-4a8d-a084-62841b3122ec\",\"recipient\":\"cGllcnJlLmxlcGV0aXRAbWV0ZW8uZnI%3D\",\"token\":\"ddf68980-7b19-4eef-8a34-88a3e32a0f71\",\"senderToken\":null,\"password\":\"2q*vbl62!FK@Z\"}'"
      ],
      "metadata": {
        "id": "YJCqiOB8X574"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modèles entraînés sur 900 époques :\n",
        "# mViT_900ep.pth comme au D.\n",
        "# mViT_0radar_900ep.pth avec, au préalable: radar = 0 x radar\n",
        "! wget https://www.grosfichiers.com/K3aaxZcSnX4_Fic8rPjJ9yZ\n",
        "! unzip K3aaxZcSnX4_Fic8rPjJ9yZ\n",
        "! rm K3aaxZcSnX4_Fic8rPjJ9yZ"
      ],
      "metadata": {
        "id": "Mte3Iwt0XVtA",
        "outputId": "3b0eb579-2d92-4a68-c709-8ade9776e200",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-25 22:47:25--  https://www.grosfichiers.com/K3aaxZcSnX4_Fic8rPjJ9yZ\n",
            "Resolving www.grosfichiers.com (www.grosfichiers.com)... 51.68.254.173\n",
            "Connecting to www.grosfichiers.com (www.grosfichiers.com)|51.68.254.173|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 52591268 (50M) [application/octet-stream]\n",
            "Saving to: ‘K3aaxZcSnX4_Fic8rPjJ9yZ’\n",
            "\n",
            "K3aaxZcSnX4_Fic8rPj 100%[===================>]  50.15M  8.91MB/s    in 7.5s    \n",
            "\n",
            "2024-04-25 22:47:34 (6.71 MB/s) - ‘K3aaxZcSnX4_Fic8rPjJ9yZ’ saved [52591268/52591268]\n",
            "\n",
            "Archive:  K3aaxZcSnX4_Fic8rPjJ9yZ\n",
            " extracting: mViT_0radar_900ep.pth   \n",
            " extracting: mViT_900ep.pth          \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# charger un checkpoint avec torch .load\n",
        "# visualiser les outputs\n",
        "\n",
        "checkpoint = torch.load('mViT_900ep.pth')\n",
        "model.load_state_dict(checkpoint['model_state_dict'])"
      ],
      "metadata": {
        "id": "NwZBpo_abXiI",
        "outputId": "c915f3d7-bc32-4169-bf7f-0de6f03319e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#visualization:\n",
        "\n",
        "model.eval()\n",
        "\n",
        "full_target, partial_target, noisy_images, traces, pairs_list = gen_image_with_pairs(6, n_pairs, n_points)\n",
        "lamedeau, pluviometres, radar, cmls_spatialises, cmls = gen_image_with_pairs(6, n_pairs, n_points)\n",
        "\n",
        "\n",
        "radar = radar.to(device)\n",
        "cmls = cmls.to(device)\n",
        "pluviometres = pluviometres.to(device)\n",
        "\n",
        "outputs = model(radar, pluviometres, cmls)\n",
        "\n",
        "radar = radar.cpu()\n",
        "cmls = cmls.cpu()\n",
        "pluviometres = pluviometres.cpu()\n",
        "outputs = outputs.cpu().detach()\n",
        "\n",
        "# lame d'eau \"idéale\"\n",
        "fig1 = plt.figure(1, figsize=(36, 6))\n",
        "voir_batch2D(lamedeau, 6, fig1, k=0, min_scale=0, max_scale=1)\n",
        "\n",
        "# images radar (bruitées)\n",
        "fig2 = plt.figure(2, figsize=(36, 6))\n",
        "voir_batch2D(radar, 6, fig2, k=0, min_scale=0, max_scale=1)\n",
        "\n",
        "# Commercial Microwave Links (cmls)\n",
        "fig3 = plt.figure(3, figsize=(36, 6))\n",
        "voir_batch2D(cmls_spatialises, 6, fig3, k=0, min_scale=0, max_scale=1)\n",
        "\n",
        "# Superposition Commercial Microwave Links (CMLs), pluviomètres et radar\n",
        "fig3 = plt.figure(3, figsize=(36, 6))\n",
        "voir_batch2D(outputs, 6, fig3, k=0, min_scale=0, max_scale=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "oThorTSX7jE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question intéressante** : \\\\\n",
        "Le transformer parvient-il à exploiter les valeurs de pluviomètres et des cmls  ?"
      ],
      "metadata": {
        "id": "IbqCfN9he7Bw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bibliographie :  [Jaegle et al. 2020](https://arxiv.org/abs/1811.12739)"
      ],
      "metadata": {
        "id": "Asx8jHYKU7wL"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}