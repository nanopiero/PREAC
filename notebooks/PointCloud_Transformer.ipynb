{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Atelier 5 : Débruitage avec PointCloud - une approche plus frugale"
      ],
      "metadata": {
        "id": "-1ciEeyNevrd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mU0zdFYCLdgR"
      },
      "outputs": [],
      "source": [
        "# Imports des bibliothèques utiles\n",
        "# pour l'IA\n",
        "import torch\n",
        "# pour les maths\n",
        "import numpy as np\n",
        "# pour afficher des images et des courbes\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqz7U32_LjwB"
      },
      "outputs": [],
      "source": [
        "# Si on veut sauvegarder le notebook sur sur google drive\n",
        "# from google.colab import drive\n",
        "# import os\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/nanopiero/PREAC.git"
      ],
      "metadata": {
        "id": "VMhc4--pzPdB",
        "outputId": "a421259c-faf5-437a-f26b-483d7ea2e8d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'PREAC'...\n",
            "remote: Enumerating objects: 110, done.\u001b[K\n",
            "remote: Counting objects: 100% (110/110), done.\u001b[K\n",
            "remote: Compressing objects: 100% (107/107), done.\u001b[K\n",
            "remote: Total 110 (delta 56), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (110/110), 7.18 MiB | 10.25 MiB/s, done.\n",
            "Resolving deltas: 100% (56/56), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install einops"
      ],
      "metadata": {
        "id": "qjk2wcBp1-sZ",
        "outputId": "fd8ea489-06a3-49ed-977c-75e791a42572",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.7.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A. Découverte du problème"
      ],
      "metadata": {
        "id": "rPIFraX86pZ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ici, on s'emploie à une tâche un peu différente:\n",
        "# détecter les pixels associés aux disques.\n",
        "# Il s'agit donc de segmentation sémantique.\n",
        "\n",
        "import PREAC.utile_Transformers\n",
        "import importlib  # Import the importlib module\n",
        "importlib.reload(PREAC.utile_Transformers)  # Reload the module\n",
        "from PREAC.utile_Transformers import gen_pointnet, voir_batch2D, \\\n",
        "                                     get_random_xy_triplets, plot_triplets\n",
        "\n",
        "batch_size = 6\n",
        "\n",
        "N = 1000\n",
        "M = 1100\n",
        "images, targets, input_points, target_list, target_points  = gen_pointnet(batch_size, N, M)\n",
        "\n",
        "# Entrées x : images\n",
        "fig1 = plt.figure(1, figsize=(36, 6))\n",
        "voir_batch2D(images, 6, fig1, k=0, min_scale=0, max_scale=1)\n",
        "\n",
        "# Cibles y : classe par pixel\n",
        "fig2 = plt.figure(2, figsize=(36, 6))\n",
        "voir_batch2D(targets, 6, fig2, k=0, min_scale=0, max_scale=1)"
      ],
      "metadata": {
        "id": "uBvv7mzq8SXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Seulement, au lieu d'aborder le problème avec des images\n",
        "# nous allons essayer d'utliser des nuages de points.\n",
        "# Pour créer ces nuages, nous avons échantilloné densément les zones\n",
        "# associées aux zones non nulles de l'image d'entrée.\n",
        "# Notez que le nuage est tridimensionnel, la troisième coordonnée\n",
        "# étant fournie par la valeur au pixel dans l'image.\n",
        "# La cble est aussi un nuage de point. L'ltitude vaut 1 pour les pixels\n",
        "# associés à des disques.\n",
        "\n",
        "for i in range(batch_size):\n",
        "  print(i)\n",
        "  plot_triplets(input_points[i].transpose(0,1).cpu())\n",
        "  plot_triplets(target_points[i].transpose(0,1).cpu())\n"
      ],
      "metadata": {
        "id": "gvc2M5GFAy9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## B. Entraînement d'un PointNet"
      ],
      "metadata": {
        "id": "Oi-tMb6eVseg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PREAC.utile_Transformers import PointNetDenseCls, feature_transform_regularizer\n",
        "\n",
        "pointnet = PointNetDenseCls(k=2, feature_transform=True).cuda()\n",
        "optimizer = torch.optim.Adam(pointnet.parameters(), lr=0.0005, betas=(0.9, 0.999))\n",
        "device = torch.device('cuda:0')\n",
        "pointnet = pointnet.to(device)\n",
        "\n",
        "\n",
        "# Fonction de coût:\n",
        "import torch.nn.functional as F\n",
        "loss_function = F.nll_loss"
      ],
      "metadata": {
        "id": "S04tXJXHQWJ4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "n_epochs = 50\n",
        "n_batch_per_epoch = 10\n",
        "N = 1000\n",
        "M = 1100\n",
        "\n",
        "\n",
        "for epoch in range(1,n_epochs):\n",
        "  print('epoch : ', epoch)\n",
        "  for batch in range(1,n_batch_per_epoch):\n",
        "    _, _, input_points, target_list, _ = gen_pointnet(batch_size, N, M)\n",
        "\n",
        "    # On n'utilise que les points :\n",
        "    input_points = input_points.to(device)\n",
        "    target_list = target_list.to(device)\n",
        "\n",
        "    # Init de l'optimizer\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    proba_pred_list, _ , trans_feat = pointnet(input_points)\n",
        "    proba_pred_list = proba_pred_list.transpose(1,2)\n",
        "    loss = loss_function(proba_pred_list, target_list)\n",
        "\n",
        "    # un peu de régularisation ici :\n",
        "    loss += feature_transform_regularizer(trans_feat) * 0.001\n",
        "\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    pred_list = proba_pred_list.data.max(1)[1]\n",
        "    correct = pred_list.eq(target_list.data).cpu().sum()\n",
        "    print('[%d: %d] train loss: %f accuracy: %f' % (epoch, batch, loss.item(), correct.item()/float(batch_size * pred.size(2))))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CNW_PJ_aAkBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#snippet pour le tracé des solutions :\n",
        "_, _, input_points, _ , target_points  = gen_pointnet(6, N, M)\n",
        "\n",
        "# Il faut construire les prédictions.\n",
        "proba_pred_list, _, _ = pointnet(input_points.to(device))\n",
        "pred_list = proba_pred_list.transpose(1,2).max(1)[1].cpu().unsqueeze(1)\n",
        "\n",
        "preds_points = torch.cat((input_points[:,:2,:], preds_list), dim=1)\n",
        "\n",
        "# Si l'on veut comparer la cible à la sortie :\n",
        "# xeq = torch.cat((input_points[:,:2,:], preds_list.max(1)[1].eq(uy).unsqueeze(1)), dim = 1)\n",
        "\n",
        "\n",
        "for i in range(6):\n",
        "  print(i)\n",
        "  plot_triplets(input_points[i].transpose(0,1))\n",
        "  plot_triplets(target_points[i].transpose(0,1))\n",
        "  plot_triplets(preds_points[i].transpose(0,1).cpu().detach())\n"
      ],
      "metadata": {
        "id": "iP9VTIEfbpCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Questions intéressantes** : \\\\\n",
        "En quoi cette approche est-elle plus frugale ?\n",
        "Le résultat est-il satisfaisant ? \\\\\n",
        "Quel est le problème ?"
      ],
      "metadata": {
        "id": "swlYi8RgblqY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## C. Entraînement d'un PointNet++"
      ],
      "metadata": {
        "id": "AQcej0hicN2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# On test avec pointNet 2:\n",
        "! git clone https://github.com/yanx27/Pointnet_Pointnet2_pytorch.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ptMPfIXLCVF",
        "outputId": "5d992ad1-7a18-4b9b-c172-4ba671afa4c1"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Pointnet_Pointnet2_pytorch'...\n",
            "remote: Enumerating objects: 842, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 842 (delta 7), reused 12 (delta 5), pack-reused 826\u001b[K\n",
            "Receiving objects: 100% (842/842), 68.77 MiB | 32.56 MiB/s, done.\n",
            "Resolving deltas: 100% (485/485), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! ls"
      ],
      "metadata": {
        "id": "iVa0p2jnEzz4",
        "outputId": "bc04bcec-92c9-428e-e593-237930c8af4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pointnet_Pointnet2_pytorch  PREAC  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('Pointnet_Pointnet2_pytorch')\n",
        "import sys\n",
        "sys.path.append('/content/Pointnet_Pointnet2_pytorch')\n",
        "import importlib\n",
        "MODEL = importlib.import_module('models.pointnet2_sem_seg_msg')"
      ],
      "metadata": {
        "id": "-Rt1gpwPMDCG"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def weights_init(m):\n",
        "#     classname = m.__class__.__name__\n",
        "#     if classname.find('Conv2d') != -1:\n",
        "#         torch.nn.init.xavier_normal_(m.weight.data)\n",
        "#         torch.nn.init.constant_(m.bias.data, 0.0)\n",
        "#     elif classname.find('Linear') != -1:\n",
        "#         torch.nn.init.xavier_normal_(m.weight.data)\n",
        "#         torch.nn.init.constant_(m.bias.data, 0.0)\n",
        "def inplace_relu(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('ReLU') != -1:\n",
        "        m.inplace=True\n",
        "\n",
        "# def bn_momentum_adjust(m, momentum):\n",
        "#     if isinstance(m, torch.nn.BatchNorm2d) or isinstance(m, torch.nn.BatchNorm1d):\n",
        "#         m.momentum = momentum"
      ],
      "metadata": {
        "id": "vitUABuGQnRm"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASSES = 2\n",
        "\n",
        "def inplace_relu(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('ReLU') != -1:\n",
        "        m.inplace=True\n",
        "\n",
        "pointnet2 = MODEL.get_model(NUM_CLASSES).cuda()\n",
        "pointnet2.apply(inplace_relu)\n",
        "criterion = MODEL.get_loss().cuda()\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(\n",
        "    pointnet2.parameters(),\n",
        "    lr=0.001,\n",
        "    betas=(0.9, 0.999),\n",
        "    eps=1e-08\n",
        ")\n"
      ],
      "metadata": {
        "id": "BJi7NYKnQuK9"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "N = 500\n",
        "M = 600\n",
        "n_epochs = 50\n",
        "\n",
        "for epoch in range(1,n_epochs):\n",
        "  print('epoch : ', epoch)\n",
        "  for batch in range(1,n_batch_per_epoch):\n",
        "    _, _, input_points, target_list, _ = gen_pointnet(batch_size, N, M)\n",
        "\n",
        "    input_points = input_points.cuda()\n",
        "    target_list = target_list.cuda()\n",
        "\n",
        "    # On se rapporte à des features tridimensionnel pour pourvoir appliquer le\n",
        "    # modèle défini dans le github de yanx27 (on n'a pas la main sur cet aspect)\n",
        "    input_points = torch.cat((input_points, input_points, input_points), dim = 1)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    seg_pred, trans_feat = pointnet2(input_points)\n",
        "\n",
        "    # Méthode de comparaison altenrantive à celle utilisée au B:\n",
        "    # on applatit les vecteurs avant comparaison\n",
        "    seg_pred = seg_pred.contiguous().view(-1, NUM_CLASSES)\n",
        "    target = target_list.view(-1, 1)[:, 0]\n",
        "    weights = None\n",
        "    loss = F.nll_loss(seg_pred, target) #, weight=weight)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # pred = pred.transpose(1,2)\n",
        "    # loss = F.nll_loss(pred, uy)\n",
        "    # print(trans_feat)\n",
        "    # loss += feature_transform_regularizer(trans_feat) * 0.001\n",
        "\n",
        "\n",
        "    pred_choice = seg_pred.data.max(1)[1]\n",
        "    correct = pred_choice.eq(target.data.view(-1, 1)[:, 0]).cpu().sum()\n",
        "    print('[%d: %d] train loss: %f accuracy: %f' % (epoch, batch, loss.item(), correct.item()/float(seg_pred.size(0))))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rJ0xoWBh3meW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#snippet pour le tracé des solutions :\n",
        "_, _, input_points, _ , target_points  = gen_pointnet(6, N, M)\n",
        "\n",
        "# Il faut construire les prédictions.\n",
        "input_points = input_points.to(device)\n",
        "\n",
        "input_points = torch.cat((input_points, input_points, input_points), dim = 1)\n",
        "proba_pred_list, _ = classifier(input_points)\n",
        "\n",
        "# Retour sur CPU\n",
        "input_points = input_points.cpu()\n",
        "pred_list = proba_pred_list.transpose(1,2).max(1)[1].cpu().unsqueeze(1)\n",
        "\n",
        "pred_points = torch.cat((input_points[:,:2,:], pred_list), dim=1)\n",
        "\n",
        "# Si l'on veut comparer la cible à la sortie :\n",
        "# xeq = torch.cat((input_points[:,:2,:], preds_list.max(1)[1].eq(uy).unsqueeze(1)), dim = 1)\n",
        "\n",
        "\n",
        "for i in range(6):\n",
        "  print(i)\n",
        "  plot_triplets(input_points[i].transpose(0,1))\n",
        "  plot_triplets(target_points[i].transpose(0,1))\n",
        "  plot_triplets(pred_points[i].transpose(0,1).cpu().detach())"
      ],
      "metadata": {
        "id": "ZLt5NRF4b_m2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question intéressante** : \\\\\n",
        "Le résultat est-il satisfaisant ? \\\\\n",
        "Que se passe-t-il si l'on joue sur les nombres de points présentés au réseau."
      ],
      "metadata": {
        "id": "rAUcpqw_luI4"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}